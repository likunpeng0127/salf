#!/usr/bin/env python
# -*- encoding: utf-8 -*-

"""
æœè£…éƒ¨ä½æå–å·¥å…·
æå–äººä½“è§£æç»“æœä¸­çš„æ¯ä¸ªéƒ¨ä½ï¼Œç”¨äºäº¤äº’å¼æœè£…æ£€æµ‹
"""

import os
import numpy as np
from PIL import Image
import argparse
import json

# æ•°æ®é›†æ ‡ç­¾å®šä¹‰
DATASET_LABELS = {
    'lip': ['Background', 'Hat', 'Hair', 'Glove', 'Sunglasses', 'Upper-clothes', 'Dress', 'Coat',
            'Socks', 'Pants', 'Jumpsuits', 'Scarf', 'Skirt', 'Face', 'Left-arm', 'Right-arm',
            'Left-leg', 'Right-leg', 'Left-shoe', 'Right-shoe'],
    'atr': ['Background', 'Hat', 'Hair', 'Sunglasses', 'Upper-clothes', 'Skirt', 'Pants', 'Dress', 'Belt',
            'Left-shoe', 'Right-shoe', 'Face', 'Left-leg', 'Right-leg', 'Left-arm', 'Right-arm', 'Bag', 'Scarf'],
    'pascal': ['Background', 'Head', 'Torso', 'Upper Arms', 'Lower Arms', 'Upper Legs', 'Lower Legs']
}

# æœè£…ç›¸å…³çš„ç±»åˆ«ï¼ˆå¯ä»¥é«˜äº®çš„éƒ¨åˆ†ï¼‰
CLOTHING_CATEGORIES = {
    'lip': {
        'Hat': 1, 'Upper-clothes': 5, 'Dress': 6, 'Coat': 7,
        'Socks': 8, 'Pants': 9, 'Jumpsuits': 10, 'Scarf': 11, 'Skirt': 12,
        'Left-shoe': 18, 'Right-shoe': 19
    },
    'atr': {
        'Hat': 1, 'Upper-clothes': 4, 'Skirt': 5, 'Pants': 6, 'Dress': 7, 'Belt': 8,
        'Left-shoe': 9, 'Right-shoe': 10, 'Bag': 16, 'Scarf': 17
    },
    'pascal': {
        'Torso': 2
    }
}


def extract_part_mask(parsing_result, part_id):
    """
    æå–å•ä¸ªéƒ¨ä½çš„äºŒå€¼æ©ç 
    
    Args:
        parsing_result: è§£æç»“æœæ•°ç»„ (H, W)ï¼Œæ¯ä¸ªåƒç´ å€¼ä»£è¡¨ç±»åˆ« ID
        part_id: è¦æå–çš„éƒ¨ä½ ID
    
    Returns:
        äºŒå€¼æ©ç æ•°ç»„ï¼Œè¯¥éƒ¨ä½ä¸º 255ï¼Œå…¶ä»–ä¸º 0
    """
    mask = np.zeros_like(parsing_result, dtype=np.uint8)
    mask[parsing_result == part_id] = 255
    return mask


def extract_all_parts(parsing_path, output_dir, dataset='lip'):
    """
    æå–æ‰€æœ‰éƒ¨ä½çš„æ©ç 
    
    Args:
        parsing_path: è§£æç»“æœå›¾ç‰‡è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        dataset: æ•°æ®é›†ç±»å‹
    """
    # è¯»å–è§£æç»“æœ
    parsing_img = Image.open(parsing_path)
    parsing_result = np.array(parsing_img)
    
    # è·å–æ ‡ç­¾åˆ—è¡¨
    labels = DATASET_LABELS[dataset]
    clothing_cats = CLOTHING_CATEGORIES[dataset]
    
    # è·å–å›¾ç‰‡åç§°
    img_name = os.path.basename(parsing_path).replace('.png', '')
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    parts_dir = os.path.join(output_dir, img_name + '_parts')
    os.makedirs(parts_dir, exist_ok=True)
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata = {
        'image_name': img_name,
        'dataset': dataset,
        'parts': [],
        'clothing_parts': []
    }
    
    # æå–æ¯ä¸ªå­˜åœ¨çš„éƒ¨ä½
    unique_ids = np.unique(parsing_result)
    print(f"ğŸ“Š å›¾ç‰‡ {img_name} åŒ…å« {len(unique_ids)} ä¸ªéƒ¨ä½:")
    
    for part_id in unique_ids:
        if part_id >= len(labels):
            continue
            
        label = labels[part_id]
        
        # æå–æ©ç 
        mask = extract_part_mask(parsing_result, part_id)
        
        # è®¡ç®—è¯¥éƒ¨ä½çš„åƒç´ æ•°é‡
        pixel_count = np.sum(mask > 0)
        percentage = (pixel_count / mask.size) * 100
        
        print(f"  - {label} (ID: {part_id}): {pixel_count} åƒç´  ({percentage:.2f}%)")
        
        # ä¿å­˜æ©ç 
        mask_path = os.path.join(parts_dir, f'{part_id:02d}_{label.replace(" ", "_")}.png')
        Image.fromarray(mask).save(mask_path)
        
        # æ·»åŠ åˆ°å…ƒæ•°æ®
        part_info = {
            'id': int(part_id),
            'name': label,
            'pixel_count': int(pixel_count),
            'percentage': float(percentage),
            'mask_path': os.path.relpath(mask_path, output_dir)
        }
        metadata['parts'].append(part_info)
        
        # æ ‡è®°æœè£…ç±»åˆ«
        if label in clothing_cats:
            metadata['clothing_parts'].append(part_info)
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata_path = os.path.join(parts_dir, 'metadata.json')
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… å®Œæˆï¼å…±æå– {len(metadata['parts'])} ä¸ªéƒ¨ä½")
    print(f"   å…¶ä¸­æœè£…éƒ¨ä½: {len(metadata['clothing_parts'])} ä¸ª")
    print(f"   è¾“å‡ºç›®å½•: {parts_dir}")
    
    return metadata


def create_overlay_image(original_img_path, parsing_path, part_id, output_path, alpha=0.7):
    """
    åˆ›å»ºå åŠ é«˜äº®çš„å›¾ç‰‡ï¼ˆç”¨äºäº¤äº’å¼æ˜¾ç¤ºï¼‰
    
    Args:
        original_img_path: åŸå§‹å›¾ç‰‡è·¯å¾„
        parsing_path: è§£æç»“æœè·¯å¾„
        part_id: è¦é«˜äº®çš„éƒ¨ä½ ID
        output_path: è¾“å‡ºè·¯å¾„
        alpha: é€æ˜åº¦
    """
    # è¯»å–å›¾ç‰‡
    original = Image.open(original_img_path).convert('RGBA')
    parsing_img = Image.open(parsing_path)
    parsing_result = np.array(parsing_img)
    
    # è°ƒæ•´è§£æç»“æœå¤§å°åˆ°åŸå›¾å¤§å°
    if parsing_result.shape != (original.height, original.width):
        parsing_result = np.array(Image.fromarray(parsing_result).resize(
            (original.width, original.height), Image.NEAREST
        ))
    
    # åˆ›å»ºé«˜äº®å±‚
    highlight = np.zeros((original.height, original.width, 4), dtype=np.uint8)
    mask = parsing_result == part_id
    highlight[mask] = [255, 255, 0, int(255 * alpha)]  # é»„è‰²é«˜äº®
    
    # å åŠ 
    highlight_img = Image.fromarray(highlight, 'RGBA')
    result = Image.alpha_composite(original, highlight_img)
    result.save(output_path)


def batch_extract(input_dir, output_dir, dataset='lip'):
    """
    æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰è§£æç»“æœ
    
    Args:
        input_dir: è¾“å…¥ç›®å½•ï¼ˆåŒ…å«è§£æç»“æœ PNGï¼‰
        output_dir: è¾“å‡ºç›®å½•
        dataset: æ•°æ®é›†ç±»å‹
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰ PNG æ–‡ä»¶
    png_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
    
    print(f"ğŸ” æ‰¾åˆ° {len(png_files)} ä¸ªè§£æç»“æœæ–‡ä»¶\n")
    
    all_metadata = []
    for png_file in png_files:
        parsing_path = os.path.join(input_dir, png_file)
        print(f"å¤„ç†: {png_file}")
        metadata = extract_all_parts(parsing_path, output_dir, dataset)
        all_metadata.append(metadata)
        print()
    
    # ä¿å­˜æ‰¹é‡å…ƒæ•°æ®
    batch_metadata_path = os.path.join(output_dir, 'batch_metadata.json')
    with open(batch_metadata_path, 'w', encoding='utf-8') as f:
        json.dump(all_metadata, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å¤„ç†äº† {len(png_files)} å¼ å›¾ç‰‡")
    print(f"æ‰¹é‡å…ƒæ•°æ®: {batch_metadata_path}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="æœè£…éƒ¨ä½æå–å·¥å…·")
    parser.add_argument('--input', type=str, required=True, help='è§£æç»“æœå›¾ç‰‡æˆ–ç›®å½•')
    parser.add_argument('--output', type=str, required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--dataset', type=str, default='lip', choices=['lip', 'atr', 'pascal'],
                        help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--batch', action='store_true', help='æ‰¹é‡å¤„ç†æ¨¡å¼')
    
    args = parser.parse_args()
    
    if args.batch:
        batch_extract(args.input, args.output, args.dataset)
    else:
        extract_all_parts(args.input, args.output, args.dataset)

